##### 消息队列的作用是啥

1. 服务解耦，生产者和消费者的解耦
2. 削峰填谷
3. 可以持久化，数据也可以保存下来
4. 一定程度起到了限流的作用

##### kafka名词解释

生产者：消息的产生方

消费者：消息的消费方

broker：kafka服务器，负责接受消息，持久化消息，提供消息给消费者

topic：主题

Partition：分区，一个topic下有m个分区，每个分区是一组有序的消息日志，分区编号从0开始

Replica：副本，备份机制，一个partition可以有多个副本，不同副本分布在不同的broker上，但是副本只可以有一个 领导者副本，其他都是追随者副本

TPS: 消费者吞吐量

Consumer Group：消费者组，多个消费者组成的一个逻辑概念，一条消息，一个组只能有一个消费者消费

Consumer Offset：哪个消费者 消费哪个消息的 哪个分区的 什么位置。

重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。

至此我们能够完整地串联起 Kafka 的三层消息架构：

第一层是主题层，每个主题可以配置 M 个分区，而每个分区又可以配置 N 个副本。

第二层是分区层，每个分区的 N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N-1 个副本是追随者副本，只是提供数据冗余之用。

第三层是消息层，分区中包含若干条消息，每条消息的位移从 0 开始，依次递增。最后，客户端程序只能与分区的领导者副本进行交互。

##### Kafka架构可以简单说下？

kafka主要 由多个broker组成的集群，每个broker下面可以容纳多个topic，每个topic下面会细分多个分区，从0开始，但并不是所有分区都在一个机器上面，每个分区又有多个备份，备份中分主从备份，主从备份也是分布在多个broker上，从而保证了消息数据的不丢失。consumer发送消息到 某个topic下，根据分区算法自动发送到某个分区，消费者则从某个broker上的某个分区开始主动拉取消息发送。

##### kafka高可用是怎么做的

kafka高可用主要是得益于他的架构设计，分区的多副本设计，一个分区下会有多个副本，其中会有一个leader副本，其他是follower副本，当某个broker挂掉以后，如果broker上的follower 宕机了，那么不影响，因为kafka只会跟leader副本交互，如果leader副本宕机了，那剩下的所有的副本会在zk的帮助下选举出一个新的leader，相当于把故障转移了，而kafka设计的leader和follower之间是数据同步的，相当于冗余备份。通过这种方式kafka达到了数据备份， 故障转移 + 高可用。

另外一方面，kafka的ack参数也确保了数据的不丢失，也是可以帮助到高可用。kafka把所有的副本 leader 和 follower 只要是有效在同步数据，那会放在ISR的集合中，当发送消息的时候

ack=0，表示只要producer发送成功了，那消息就是发送成功了

ack=1,表示只要producer 发送消息成功，并且leader 落盘了，那就是发送成功了，默认配置

Ack = all，表是不仅leader要落盘，还是ISR中其他follower也落盘才算发送成功。

所以通过这种配置来保证数据不丢失，高可用，但是也不是100%有效的，如果只有ISR里只有一个leader 没follower 该丢失还是要丢失。

##### kafka副本的好处是啥？

正常副本：

1. 数据备份，数据冗余
2. 提供了更高的集群伸缩性，可以扩展机器来提高读写性能，横向扩展
3. 通过把副本数据放在离用户更近的地方，来降低数据延迟

kafka的副本

1. 数据备份，数据冗余，高可用。

所谓副本本质就是一个只能追加写消息的提交日志。根据 Kafka 副本机制的定义，同一个分区下的所有副本保存有相同的消息序列，这些副本分散保存在不同的 Broker 上，从而能够对抗部分 Broker 宕机带来的数据不可用。

##### Kafka 为什么 follower副本不提供服务

1. 避免数据延迟，写的数据立刻可见
2. 数据延迟带来的  consumer 消费同一个 partition消息可能会有 丢失 的问题。

##### ISR 如何定义，条件是啥？

1. 有参数确认，默认 follower 落后 leader 10秒就 不算了，10s以内 还在ISR内。 ISR会动态收缩扩容

##### 什么是UnClean选举？

副本全挂掉了，必须要选举一个新的副本，但是ISR里又没有副本了，只能在非ISR副本里选举，叫做unclean选举。有参数配置控制。

开启 就相当于 提高了可用性，但是牺牲了 数据一致性， 关闭就相当于 牺牲了可用性，但是可以保障数据一致性。等待leader恢复

##### Kafka如何保障消息不丢失？

1. producer端通过acks =all 来保障消息的不丢失，或者代码里 使用  send(message, callback) 来接收发送失败的 callback
2. consumer段如果是多线程消费消息的话，最好手动提交offerset，否则容易导致重复消费数据，或者消费失败数据。

##### Kafka消息的可靠性保障是什么 ？

所谓的消息交付可靠性保障，是指 Kafka 对 Producer 和 Consumer 要处理的消息提供什么样的承诺。常见的承诺有以下三种：

- 最多一次（at most once）：消息可能会丢失，但绝不会被重复发送。

- 至少一次（at least once）：消息不会丢失，但有可能被重复发送。

- 精确一次（exactly once）：消息不会丢失，也不会被重复发送。

Kafka默认提供交付可靠性保障是至少一次。

为什么默认是至少一次，因为1、至少一次实现起来不复杂，2、consumer 保持幂等比较简单 3、事务producer 机制复杂。

Kafka消息交付可靠性保障以及精确处理一次语义通过两种机制来实现的：冥等性（Idempotence）和事务（Transaction）。

幂等性主要解决的是 同一个partition下的同一个分区可以做到 精确一次不重复。

###### 幂等性原理：

producer启动的时候会有一个pid，partion，以及每次发消息有个 sequence num，每发一个消息 自增。这三者组成了一个唯一键，发送以后producer 会判断是否已发送，已发送那就不再发了，这个是producer的幂等性。

每次producer 重启后 pid会变。

类似地，Broker 端也会为每个`<PID, Topic, Partition>`维护一个序号，并且每次 Commit 一条消息时将其对应序号递增。对于接收的每条消息，如果其序号比 Broker 维护的序号（即最后一次 Commit 的消息的序号）大一，则 Broker 会接受它，否则将其丢弃：

- 如果消息序号比 Broker 维护的序号大一以上，说明中间有数据尚未写入，也即乱序，此时 Broker 拒绝该消息，Producer 抛出`InvalidSequenceNumber`
- 如果消息序号小于等于 Broker 维护的序号，说明该消息已被保存，即为重复消息，Broker 直接丢弃该消息，Producer 抛出`DuplicateSequenceNumber`

上述设计解决了 0.11.0.0 之前版本中的两个问题：

- Broker 保存消息后，发送 ACK 前宕机，Producer 认为消息未发送成功并重试，造成数据重复
- 前一条消息发送失败，后一条消息发送成功，前一条消息重试后成功，造成数据乱序

###### 事务原理

kafka事务能够保证将消息原子性地写入到多个分区中。这批消息要么全部写入成功，要么全部失败。另外，事务型 Producer 也不惧进程的重启。Producer 重启回来后，Kafka 依然保证它们发送消息的精确一次处理。

![CleanShot 2023-03-18 at 02.07.35@2x](/Users/jazz/Library/Application Support/CleanShot/media/media_CV7dZF0Gf8/CleanShot 2023-03-18 at 02.07.35@2x.png)

kafka解决事务的原理核心： 2PC 引入了 事务协调器的组件帮助完成分布式事务。

1. 每个broker都会有个事务协调器。启动的时候，producer 会跟 事务协调器要一个pid，重启后pid也是相同的。
2. producer开启事务，发送消息以后，消息会打上事务的标，同时也会告诉协调器 我向那个partion里发
3. 协调器收到commit 或者abort消息，在内置 topic _transaction_state 频道里 发送消息询问对应的broker ，消息是否落盘。
4. 对应broker的topic 收到消息后确认是否落盘，落盘成功则 发送成功消息，否则失败
5. 事务协调器收到 成功/失败消息后，反馈 producer 事务成功还是失败

分布式事务流程就这样。

##### kafka consumer是多线程的还是单线程的？

老版本有多线程的consumer，新版本单线程，也有多线程的解决方案。consumer实例是线程不安全的，共享会报错，但是有api可以多个线程唤醒操作，单线程优点

1. 代码逻辑简单
2. 移植到其他语言方便
3. 把消息消费多线程的选择 留给使用者

多线程方案主要两种

1. 每个线程自己的consumer
2. 业务消费代码使用多线程，然后手动commit。

优缺点比较

![](https://static001.geekbang.org/resource/image/84/0c/84dc0edb73f203b55808b33ca004670c.jpg?wh=3927*1716)

##### kafka如何保障消息的顺序性

顺序性包括局部有序和全局有序

全局有序：不支持，只能通过 只设置一个partion来实现全局有序，退化成局部有序。

局部有序：业务key 来实现partion key的逻辑就可以了。例如：Topic消息是订单的流水表，包含订单orderId，业务要求同一个orderId的消息需要按照生产顺序进行消费。

重试对于消息顺序性是有影响的，比如 producer 发送了 A ，B 2个消息，A发送失败了，B成功了，然后A重试，但是broker上是先收到了B再收到了A，正确顺序应该是AB。

解决方案：

1. 有个参数，broker响应producer ack之前 允许发送多少消息，设置为1 则是一次就发一个消息，然后ack才另外发一个消息。

   max.in.flight.requests.per.connection = 1

2. max.in.flight.requests.per.connection =1会严重影响性能，那只能在consumer段做业务 包容，消费到这种错误的BA消息顺序 然后报警，打标，重试。

##### 消息堆积怎么解决

1. 确认业务逻辑是否 耗时，比较耗时的 那发的也要注意，或者纯异步 保存到数据库里处理
2. 不耗时，是否是 producer过快 还是 comsumer 过慢，多线程处理

##### 什么是Kafka的重平衡？

consumer 重平衡

就是重新分配consumer的过程。为了尽量达到所有consumer 数据消费量 压力一致。

重平衡触发的三个条件

- 组成员数量发生变化。
- 订阅主题数量发生变化。
- 订阅主题的分区数发生变化。

重平衡主要靠 consumer之间的心跳来进行通知，流程如下

1. 新增consumer 想 broker的 协调者发送消息，需要假如 consumer group
2. broker 通知所有的consumer 需要重平衡
3. 所有新的broker 发送消息告诉 协调者 我需要加入xx  consumer group
4. 协调者 选出最早的一个 发送加入 group请求的 consumer
5. 协调者把  所有consumer 消费的信息 以及topic 信息全部发送给 leader consumer
6. leader consumer 把 重新分配的方案 发送给 协调者
7. 协调者 把对应consumer 消费的最新消息 分别发送给每个 consumer
8. 结束

重平衡从broker视角 主要分三种

1. 新的消费者加入
2. 旧的消费者退出，主动发送leave group命令离开
3. 旧的消费者 崩溃退出，有具体心跳参数控制，心跳发现 离开

在重平衡之前，协调者会要求所有consumer 尽快在一个时间之内 提交自己的offset。在整个重平衡过程中，组内所有消费者实例都会暂停消费。

##### 消息队列横向对比？











